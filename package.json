{
  "name": "search-text-tokenizer",
  "version": "2.0.0",
  "description": "A tokenizer for Google-like search queries",
  "main": "index",
  "dependencies": {
    "lodash": "^4.0.0"
  },
  "devDependencies": {
    "mocha": "*",
    "should": "*"
  },
  "scripts": {
    "test": "make test"
  },
  "repository": "tatsuyaoiw/search-text-tokenizer",
  "bugs": "https://github.com/tatsuyaoiw/search-text-tokenizer/issues",
  "author": "Tatsuya Oiwa <tatsuyaoiw@gmail.com>",
  "license": "MIT",
  "keywords": [
    "tokenizer",
    "search",
    "text",
    "query",
    "keyword"
  ]
}
